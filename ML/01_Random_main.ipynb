{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2225eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd44d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "learning_rate=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c46e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "data_in=np.loadtxt('./data/Re_100/input_u_fake.dat')\n",
    "data_out=np.loadtxt('./data/Re_100/output_p.dat')\n",
    "x=torch.Tensor(data_in)\n",
    "y=torch.Tensor(data_out)\n",
    "loader=DataLoader(TensorDataset(x, y), batch_size=204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c481de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 6724])\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Prepare data-1/2\n",
    "# DataLoader wraps a Dataset and provides minibatches, shuffling, multithreading, for you\n",
    "x=torch.randn(64, 6724, device=device) #Input dimension of 1000\n",
    "y=torch.randn(64, 6724, device=device) #Output dimension of 10 i.e, ground-truth dimension\n",
    "print(x.size())\n",
    "loader=DataLoader(TensorDataset(x, y), batch_size=6724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2927d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create model 建立model習慣建立class\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, B, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear_1=torch.nn.Linear(D_in, H)\n",
    "        self.linear_2=torch.nn.Linear(H, B)\n",
    "        self.linear_3=torch.nn.Linear(B, D_out)\n",
    "    \n",
    "    # Step 3. Forward pass-1/2    # Step 4. Backward pass-1/2\n",
    "    def forward(self, x):\n",
    "        h=self.linear_1(x)\n",
    "        h_relu=torch.nn.functional.relu(h) #為何activation and hidden layer 的實現方式不同\n",
    "        b=self.linear_2(h_relu) \n",
    "        b_relu=torch.nn.functional.relu(b)\n",
    "        y_pred=self.linear_3(b_relu) \n",
    "        return y_pred\n",
    "    \n",
    "model= TwoLayerNet(D_in=6724, H=1000, B=100, D_out=6724)\n",
    "model=model.to(device) #這行是什麼意思? A:将模型加载到相应的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f022e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a8f78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  0 ; Loss:  1.0150134563446045\n",
      "Epochs:  10 ; Loss:  0.9996188879013062\n",
      "Epochs:  20 ; Loss:  0.9963328838348389\n",
      "Epochs:  30 ; Loss:  0.9922813177108765\n",
      "Epochs:  40 ; Loss:  0.9872265458106995\n",
      "Epochs:  50 ; Loss:  0.9810537695884705\n",
      "Epochs:  60 ; Loss:  0.973750650882721\n",
      "Epochs:  70 ; Loss:  0.9652711153030396\n",
      "Epochs:  80 ; Loss:  0.9555574059486389\n",
      "Epochs:  90 ; Loss:  0.9446518421173096\n",
      "Epochs:  100 ; Loss:  0.9326510429382324\n",
      "Epochs:  110 ; Loss:  0.919552206993103\n",
      "Epochs:  120 ; Loss:  0.9054200053215027\n",
      "Epochs:  130 ; Loss:  0.8903639912605286\n",
      "Epochs:  140 ; Loss:  0.8744727969169617\n",
      "Epochs:  150 ; Loss:  0.8578102588653564\n",
      "Epochs:  160 ; Loss:  0.8404197692871094\n",
      "Epochs:  170 ; Loss:  0.8223000168800354\n",
      "Epochs:  180 ; Loss:  0.8036009669303894\n",
      "Epochs:  190 ; Loss:  0.7843625545501709\n",
      "Epochs:  200 ; Loss:  0.7646484375\n",
      "Epochs:  210 ; Loss:  0.744488000869751\n",
      "Epochs:  220 ; Loss:  0.7240378856658936\n",
      "Epochs:  230 ; Loss:  0.7033116221427917\n",
      "Epochs:  240 ; Loss:  0.6824501752853394\n",
      "Epochs:  250 ; Loss:  0.6614776849746704\n",
      "Epochs:  260 ; Loss:  0.6404606103897095\n",
      "Epochs:  270 ; Loss:  0.6194489598274231\n",
      "Epochs:  280 ; Loss:  0.598526120185852\n",
      "Epochs:  290 ; Loss:  0.5776931047439575\n",
      "Epochs:  300 ; Loss:  0.5569957494735718\n",
      "Epochs:  310 ; Loss:  0.5364890694618225\n",
      "Epochs:  320 ; Loss:  0.5162327885627747\n",
      "Epochs:  330 ; Loss:  0.49624747037887573\n",
      "Epochs:  340 ; Loss:  0.476541668176651\n",
      "Epochs:  350 ; Loss:  0.4571686089038849\n",
      "Epochs:  360 ; Loss:  0.438152939081192\n",
      "Epochs:  370 ; Loss:  0.41950446367263794\n",
      "Epochs:  380 ; Loss:  0.4012533724308014\n",
      "Epochs:  390 ; Loss:  0.38342416286468506\n",
      "Epochs:  400 ; Loss:  0.3660053610801697\n",
      "Epochs:  410 ; Loss:  0.34901994466781616\n",
      "Epochs:  420 ; Loss:  0.3324876129627228\n",
      "Epochs:  430 ; Loss:  0.31638944149017334\n",
      "Epochs:  440 ; Loss:  0.3007449805736542\n",
      "Epochs:  450 ; Loss:  0.28555095195770264\n",
      "Epochs:  460 ; Loss:  0.27082639932632446\n",
      "Epochs:  470 ; Loss:  0.25655731558799744\n",
      "Epochs:  480 ; Loss:  0.24275028705596924\n",
      "Epochs:  490 ; Loss:  0.2294045090675354\n",
      "Epochs:  500 ; Loss:  0.21653017401695251\n",
      "Epochs:  510 ; Loss:  0.2041073590517044\n",
      "Epochs:  520 ; Loss:  0.1921442747116089\n",
      "Epochs:  530 ; Loss:  0.18064114451408386\n",
      "Epochs:  540 ; Loss:  0.16958636045455933\n",
      "Epochs:  550 ; Loss:  0.15898087620735168\n",
      "Epochs:  560 ; Loss:  0.14883211255073547\n",
      "Epochs:  570 ; Loss:  0.13911376893520355\n",
      "Epochs:  580 ; Loss:  0.12983956933021545\n",
      "Epochs:  590 ; Loss:  0.12099763751029968\n",
      "Epochs:  600 ; Loss:  0.11257468909025192\n",
      "Epochs:  610 ; Loss:  0.10457086563110352\n",
      "Epochs:  620 ; Loss:  0.09698046743869781\n",
      "Epochs:  630 ; Loss:  0.08978823572397232\n",
      "Epochs:  640 ; Loss:  0.08299398422241211\n",
      "Epochs:  650 ; Loss:  0.07658503204584122\n",
      "Epochs:  660 ; Loss:  0.07055522501468658\n",
      "Epochs:  670 ; Loss:  0.06489254534244537\n",
      "Epochs:  680 ; Loss:  0.059582728892564774\n",
      "Epochs:  690 ; Loss:  0.054615844041109085\n",
      "Epochs:  700 ; Loss:  0.04997891187667847\n",
      "Epochs:  710 ; Loss:  0.04566994309425354\n",
      "Epochs:  720 ; Loss:  0.04164886474609375\n",
      "Epochs:  730 ; Loss:  0.03792816773056984\n",
      "Epochs:  740 ; Loss:  0.03448876738548279\n",
      "Epochs:  750 ; Loss:  0.03131278604269028\n",
      "Epochs:  760 ; Loss:  0.02839197963476181\n",
      "Epochs:  770 ; Loss:  0.02570144273340702\n",
      "Epochs:  780 ; Loss:  0.023233404383063316\n",
      "Epochs:  790 ; Loss:  0.02097567729651928\n",
      "Epochs:  800 ; Loss:  0.01891542412340641\n",
      "Epochs:  810 ; Loss:  0.017031358554959297\n",
      "Epochs:  820 ; Loss:  0.015317631885409355\n",
      "Epochs:  830 ; Loss:  0.013759956695139408\n",
      "Epochs:  840 ; Loss:  0.01234718132764101\n",
      "Epochs:  850 ; Loss:  0.011069591157138348\n",
      "Epochs:  860 ; Loss:  0.009909329004585743\n",
      "Epochs:  870 ; Loss:  0.008865171112120152\n",
      "Epochs:  880 ; Loss:  0.007922445423901081\n",
      "Epochs:  890 ; Loss:  0.0070726992562413216\n",
      "Epochs:  900 ; Loss:  0.006310338154435158\n",
      "Epochs:  910 ; Loss:  0.0056306179612874985\n",
      "Epochs:  920 ; Loss:  0.00501237390562892\n",
      "Epochs:  930 ; Loss:  0.004458726849406958\n",
      "Epochs:  940 ; Loss:  0.003965409472584724\n",
      "Epochs:  950 ; Loss:  0.00352595467120409\n",
      "Epochs:  960 ; Loss:  0.0031384045723825693\n",
      "Epochs:  970 ; Loss:  0.0027886575553566217\n",
      "Epochs:  980 ; Loss:  0.0024686106480658054\n",
      "Epochs:  990 ; Loss:  0.002187768928706646\n",
      "Epochs:  1000 ; Loss:  0.0019386893836781383\n",
      "Epochs:  1010 ; Loss:  0.0017177312402054667\n",
      "Epochs:  1020 ; Loss:  0.0015226798132061958\n",
      "Epochs:  1030 ; Loss:  0.00135216920170933\n",
      "Epochs:  1040 ; Loss:  0.0011943893041461706\n",
      "Epochs:  1050 ; Loss:  0.0010554351611062884\n",
      "Epochs:  1060 ; Loss:  0.0009334352798759937\n",
      "Epochs:  1070 ; Loss:  0.0008285634685307741\n",
      "Epochs:  1080 ; Loss:  0.0007313282112590969\n",
      "Epochs:  1090 ; Loss:  0.0006512433756142855\n",
      "Epochs:  1100 ; Loss:  0.0005702284979633987\n",
      "Epochs:  1110 ; Loss:  0.0005028501036576927\n",
      "Epochs:  1120 ; Loss:  0.0004436408053152263\n",
      "Epochs:  1130 ; Loss:  0.0003922377072740346\n",
      "Epochs:  1140 ; Loss:  0.00035143786226399243\n",
      "Epochs:  1150 ; Loss:  0.000306166970403865\n",
      "Epochs:  1160 ; Loss:  0.0002738403563853353\n",
      "Epochs:  1170 ; Loss:  0.00024386933364439756\n",
      "Epochs:  1180 ; Loss:  0.0002116690739057958\n",
      "Epochs:  1190 ; Loss:  0.00018514695693738759\n",
      "Epochs:  1200 ; Loss:  0.00016291769861709327\n",
      "Epochs:  1210 ; Loss:  0.00014400265354197472\n",
      "Epochs:  1220 ; Loss:  0.00013219933316577226\n",
      "Epochs:  1230 ; Loss:  0.00011367662955308333\n",
      "Epochs:  1240 ; Loss:  9.948052320396528e-05\n",
      "Epochs:  1250 ; Loss:  8.716362935956568e-05\n",
      "Epochs:  1260 ; Loss:  7.659280527150258e-05\n",
      "Epochs:  1270 ; Loss:  7.006356463534757e-05\n",
      "Epochs:  1280 ; Loss:  7.09617233951576e-05\n",
      "Epochs:  1290 ; Loss:  5.356004476197995e-05\n",
      "Epochs:  1300 ; Loss:  4.7852554416749626e-05\n",
      "Epochs:  1310 ; Loss:  4.090304355486296e-05\n",
      "Epochs:  1320 ; Loss:  3.562355414032936e-05\n",
      "Epochs:  1330 ; Loss:  3.165308589814231e-05\n",
      "Epochs:  1340 ; Loss:  3.7154637539060786e-05\n",
      "Epochs:  1350 ; Loss:  2.899068931583315e-05\n",
      "Epochs:  1360 ; Loss:  2.3931130272103474e-05\n",
      "Epochs:  1370 ; Loss:  2.0332014173618518e-05\n",
      "Epochs:  1380 ; Loss:  2.354193384235259e-05\n",
      "Epochs:  1390 ; Loss:  1.5402352801174857e-05\n",
      "Epochs:  1400 ; Loss:  1.4393332094186917e-05\n",
      "Epochs:  1410 ; Loss:  1.4219899640011135e-05\n",
      "Epochs:  1420 ; Loss:  1.392360354657285e-05\n",
      "Epochs:  1430 ; Loss:  1.0301310794602614e-05\n",
      "Epochs:  1440 ; Loss:  7.739688044239301e-06\n",
      "Epochs:  1450 ; Loss:  7.559498953924049e-06\n",
      "Epochs:  1460 ; Loss:  1.2547336154966615e-05\n",
      "Epochs:  1470 ; Loss:  1.275778777198866e-05\n",
      "Epochs:  1480 ; Loss:  5.9579956541711e-06\n",
      "Epochs:  1490 ; Loss:  4.283436283003539e-06\n",
      "Epochs:  1500 ; Loss:  3.7374431940406794e-06\n",
      "Epochs:  1510 ; Loss:  3.3785408959374763e-06\n",
      "Epochs:  1520 ; Loss:  7.735011422482785e-06\n",
      "Epochs:  1530 ; Loss:  9.042424608196598e-06\n",
      "Epochs:  1540 ; Loss:  4.373232513898984e-06\n",
      "Epochs:  1550 ; Loss:  4.486261786951218e-06\n",
      "Epochs:  1560 ; Loss:  2.305932639501407e-06\n",
      "Epochs:  1570 ; Loss:  1.7457412013754947e-06\n",
      "Epochs:  1580 ; Loss:  3.3855706078611547e-06\n",
      "Epochs:  1590 ; Loss:  1.061751572706271e-05\n",
      "Epochs:  1600 ; Loss:  3.975407253165031e-06\n",
      "Epochs:  1610 ; Loss:  5.999375389365014e-06\n",
      "Epochs:  1620 ; Loss:  5.4953588914941065e-06\n",
      "Epochs:  1630 ; Loss:  3.104463985437178e-06\n",
      "Epochs:  1640 ; Loss:  2.110110017383704e-06\n",
      "Epochs:  1650 ; Loss:  1.2775640243489761e-05\n",
      "Epochs:  1660 ; Loss:  3.5929256227973383e-06\n",
      "Epochs:  1670 ; Loss:  2.211989794886904e-06\n",
      "Epochs:  1680 ; Loss:  5.4260226534097455e-06\n",
      "Epochs:  1690 ; Loss:  2.6860177513299277e-06\n",
      "Epochs:  1700 ; Loss:  1.6341035689038108e-06\n",
      "Epochs:  1710 ; Loss:  1.0578849014564184e-06\n",
      "Epochs:  1720 ; Loss:  6.191772627062164e-06\n",
      "Epochs:  1730 ; Loss:  5.170798431208823e-06\n",
      "Epochs:  1740 ; Loss:  1.986462393688271e-06\n",
      "Epochs:  1750 ; Loss:  1.7258785192098003e-06\n",
      "Epochs:  1760 ; Loss:  7.721319889242295e-06\n",
      "Epochs:  1770 ; Loss:  2.6099062324647093e-06\n",
      "Epochs:  1780 ; Loss:  2.192719421145739e-06\n",
      "Epochs:  1790 ; Loss:  2.924901082224096e-06\n",
      "Epochs:  1800 ; Loss:  4.0427298699796665e-06\n",
      "Epochs:  1810 ; Loss:  4.486224042921094e-06\n",
      "Epochs:  1820 ; Loss:  4.38484994447208e-06\n",
      "Epochs:  1830 ; Loss:  1.3863636922906153e-06\n",
      "Epochs:  1833 ; Loss:  9.752146752362023e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1. Prepare data-2/2\n",
    "# Iterate over loader to form mini-batches\n",
    "# Batch aims to deal with memory limitation in GPU\n",
    "\n",
    "loss_epoch=[]\n",
    "loss_values = []\n",
    "\n",
    "for epochs in range(2000):\n",
    "    # Step 3. Forward pass-2/2  \n",
    "    # Feed data to model, and compute loss\n",
    "    \n",
    "    for x_batch, y_batch in loader:\n",
    "        y_pred=model(x_batch) #為何不是 model.forward(x_batch) #Forward 過程中同時建立computational graph\n",
    "        loss=torch.nn.functional.mse_loss(y_pred, y_batch) #Loss functions 是被定義在torch.nn.functional中\n",
    "        \n",
    "        # Step 4. Backward pass-2/2\n",
    "        # Compute gradient of loss wrt all model weights\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 5. Update Weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() #此步為清空，否則會影響下一步gradient的計算\n",
    "        if epochs%10==0:\n",
    "            print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "    \n",
    "    loss_epoch.append(epochs)\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    if loss<1e-6: #stop training criterion\n",
    "        print(\"Epochs: \", epochs, \"; Loss: \", loss.item())\n",
    "        break\n",
    "\n",
    "\n",
    "#Plot loss function\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_epoch, loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e796b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"01_model_jit.pth\"\n",
    "traced_net=torch.jit.trace(model, torch.randn(1,6724))\n",
    "torch.jit.save(traced_net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
